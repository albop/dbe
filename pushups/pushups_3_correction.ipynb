{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "egyptian-walter",
   "metadata": {},
   "source": [
    "# Sklearn: sparse regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-potter",
   "metadata": {},
   "source": [
    "## Predicting Breast Cancer\n",
    "\n",
    "Sklearn includes the Winsconsin breast cancer database. It associates medical outcomes for tumor observation, with several characteristics. Can a machine learn how to predict whether a cancer is benign or malignant ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-romance",
   "metadata": {},
   "source": [
    "__Import the Breast Cancer Dataset from sklearn. Describe it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5dd277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.datasets\n",
    "# the as_frame option makes the function return a dataframe\n",
    "dataset = sklearn.datasets.load_breast_cancer(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d95f530-e8de-4d2a-a8c3-2956dfc0bdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset['data']\n",
    "target = dataset['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-separation",
   "metadata": {},
   "source": [
    "__Properly train a linear logistic regression to predict cancer morbidity.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a140725-a3c1-40d6-847f-23b36d0b6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the training set and the testset\n",
    "import sklearn.model_selection\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ae05c6-8dc1-45db-bc03-573b0cf01073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(426, 30), (143, 30), (426,), (143,)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly check thes size of th samples, correspond to  what we want:\n",
    "[e.shape for e in [data_train, data_test, target_train, target_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a786e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67cfc32-ffb6-49ac-a605-98d60327c288",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/escpython/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adf5f47d-5654-405c-a7d1-92b31099c240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check the performance out of sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "975031fa-5532-4082-8d09-2b677c72f318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8951048951048951"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec354ff9-928d-4ea1-9dab-3e32aeca3a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Return the mean accuracy on the given test data and labels.\n",
       "\n",
       "In multi-label classification, this is the subset accuracy\n",
       "which is a harsh metric since you require for each sample that\n",
       "each label set be correctly predicted.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X : array-like of shape (n_samples, n_features)\n",
       "    Test samples.\n",
       "\n",
       "y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
       "    True labels for `X`.\n",
       "\n",
       "sample_weight : array-like of shape (n_samples,), default=None\n",
       "    Sample weights.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "score : float\n",
       "    Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/conda/envs/escpython/lib/python3.10/site-packages/sklearn/base.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to know what the scores represent, we can read the doc\n",
    "# it shows that score is measured by mean accuracy\n",
    "# i.e. number of correct predictions divided by total number of predictions\n",
    "model.score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72744d1b-4569-4b48-bdf2-64e8c5f83f75",
   "metadata": {},
   "source": [
    "__Bonus__: the warning message suggests to scale the data. Let's  redo the last few steps accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c804ff5c-c399-47ea-8f8e-389b49ca956e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14f90e1c-31c4-45b2-a1dc-552b7fe5444c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.373633e-16</td>\n",
       "      <td>6.868164e-17</td>\n",
       "      <td>-1.248757e-16</td>\n",
       "      <td>-2.185325e-16</td>\n",
       "      <td>-8.366672e-16</td>\n",
       "      <td>1.873136e-16</td>\n",
       "      <td>4.995028e-17</td>\n",
       "      <td>-4.995028e-17</td>\n",
       "      <td>1.748260e-16</td>\n",
       "      <td>4.745277e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.241796e-16</td>\n",
       "      <td>1.248757e-17</td>\n",
       "      <td>-3.746271e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.372638e-16</td>\n",
       "      <td>-3.371644e-16</td>\n",
       "      <td>7.492542e-17</td>\n",
       "      <td>2.247763e-16</td>\n",
       "      <td>2.622390e-16</td>\n",
       "      <td>-5.744282e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "      <td>1.000880e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.029648e+00</td>\n",
       "      <td>-2.229249e+00</td>\n",
       "      <td>-1.984504e+00</td>\n",
       "      <td>-1.454443e+00</td>\n",
       "      <td>-3.112085e+00</td>\n",
       "      <td>-1.610136e+00</td>\n",
       "      <td>-1.114873e+00</td>\n",
       "      <td>-1.261820e+00</td>\n",
       "      <td>-2.744117e+00</td>\n",
       "      <td>-1.819865e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.726901e+00</td>\n",
       "      <td>-2.223994e+00</td>\n",
       "      <td>-1.693361e+00</td>\n",
       "      <td>-1.222423</td>\n",
       "      <td>-2.682695e+00</td>\n",
       "      <td>-1.443878e+00</td>\n",
       "      <td>-1.305831e+00</td>\n",
       "      <td>-1.745063e+00</td>\n",
       "      <td>-2.160960e+00</td>\n",
       "      <td>-1.601839e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.893853e-01</td>\n",
       "      <td>-7.259631e-01</td>\n",
       "      <td>-6.919555e-01</td>\n",
       "      <td>-6.671955e-01</td>\n",
       "      <td>-7.109628e-01</td>\n",
       "      <td>-7.470860e-01</td>\n",
       "      <td>-7.437479e-01</td>\n",
       "      <td>-7.379438e-01</td>\n",
       "      <td>-7.032397e-01</td>\n",
       "      <td>-7.226392e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.749213e-01</td>\n",
       "      <td>-7.486293e-01</td>\n",
       "      <td>-6.895783e-01</td>\n",
       "      <td>-0.642136</td>\n",
       "      <td>-6.912304e-01</td>\n",
       "      <td>-6.810833e-01</td>\n",
       "      <td>-7.565142e-01</td>\n",
       "      <td>-7.563999e-01</td>\n",
       "      <td>-6.418637e-01</td>\n",
       "      <td>-6.919118e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.150816e-01</td>\n",
       "      <td>-1.046362e-01</td>\n",
       "      <td>-2.359800e-01</td>\n",
       "      <td>-2.951869e-01</td>\n",
       "      <td>-3.489108e-02</td>\n",
       "      <td>-2.219405e-01</td>\n",
       "      <td>-3.422399e-01</td>\n",
       "      <td>-3.977212e-01</td>\n",
       "      <td>-7.162650e-02</td>\n",
       "      <td>-1.782793e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.690395e-01</td>\n",
       "      <td>-4.351564e-02</td>\n",
       "      <td>-2.859802e-01</td>\n",
       "      <td>-0.341181</td>\n",
       "      <td>-4.684277e-02</td>\n",
       "      <td>-2.695009e-01</td>\n",
       "      <td>-2.182321e-01</td>\n",
       "      <td>-2.234689e-01</td>\n",
       "      <td>-1.274095e-01</td>\n",
       "      <td>-2.164441e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.693926e-01</td>\n",
       "      <td>5.841756e-01</td>\n",
       "      <td>4.996769e-01</td>\n",
       "      <td>3.635073e-01</td>\n",
       "      <td>6.361990e-01</td>\n",
       "      <td>4.938569e-01</td>\n",
       "      <td>5.260619e-01</td>\n",
       "      <td>6.469351e-01</td>\n",
       "      <td>5.307792e-01</td>\n",
       "      <td>4.709834e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.220158e-01</td>\n",
       "      <td>6.583411e-01</td>\n",
       "      <td>5.402790e-01</td>\n",
       "      <td>0.357589</td>\n",
       "      <td>5.975448e-01</td>\n",
       "      <td>5.396688e-01</td>\n",
       "      <td>5.311411e-01</td>\n",
       "      <td>7.125100e-01</td>\n",
       "      <td>4.501382e-01</td>\n",
       "      <td>4.507624e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.971288e+00</td>\n",
       "      <td>4.651889e+00</td>\n",
       "      <td>3.976130e+00</td>\n",
       "      <td>5.250529e+00</td>\n",
       "      <td>4.770911e+00</td>\n",
       "      <td>4.568425e+00</td>\n",
       "      <td>4.243589e+00</td>\n",
       "      <td>3.927930e+00</td>\n",
       "      <td>4.484751e+00</td>\n",
       "      <td>4.910919e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.094189e+00</td>\n",
       "      <td>3.885905e+00</td>\n",
       "      <td>4.287337e+00</td>\n",
       "      <td>5.930172</td>\n",
       "      <td>3.955374e+00</td>\n",
       "      <td>5.112877e+00</td>\n",
       "      <td>4.700669e+00</td>\n",
       "      <td>2.685877e+00</td>\n",
       "      <td>6.046041e+00</td>\n",
       "      <td>6.846856e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean radius  mean texture  mean perimeter     mean area  \\\n",
       "count  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
       "mean  -1.373633e-16  6.868164e-17   -1.248757e-16 -2.185325e-16   \n",
       "std    1.000880e+00  1.000880e+00    1.000880e+00  1.000880e+00   \n",
       "min   -2.029648e+00 -2.229249e+00   -1.984504e+00 -1.454443e+00   \n",
       "25%   -6.893853e-01 -7.259631e-01   -6.919555e-01 -6.671955e-01   \n",
       "50%   -2.150816e-01 -1.046362e-01   -2.359800e-01 -2.951869e-01   \n",
       "75%    4.693926e-01  5.841756e-01    4.996769e-01  3.635073e-01   \n",
       "max    3.971288e+00  4.651889e+00    3.976130e+00  5.250529e+00   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
       "mean     -8.366672e-16      1.873136e-16    4.995028e-17        -4.995028e-17   \n",
       "std       1.000880e+00      1.000880e+00    1.000880e+00         1.000880e+00   \n",
       "min      -3.112085e+00     -1.610136e+00   -1.114873e+00        -1.261820e+00   \n",
       "25%      -7.109628e-01     -7.470860e-01   -7.437479e-01        -7.379438e-01   \n",
       "50%      -3.489108e-02     -2.219405e-01   -3.422399e-01        -3.977212e-01   \n",
       "75%       6.361990e-01      4.938569e-01    5.260619e-01         6.469351e-01   \n",
       "max       4.770911e+00      4.568425e+00    4.243589e+00         3.927930e+00   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count   5.690000e+02            5.690000e+02  ...  5.690000e+02   \n",
       "mean    1.748260e-16            4.745277e-16  ... -8.241796e-16   \n",
       "std     1.000880e+00            1.000880e+00  ...  1.000880e+00   \n",
       "min    -2.744117e+00           -1.819865e+00  ... -1.726901e+00   \n",
       "25%    -7.032397e-01           -7.226392e-01  ... -6.749213e-01   \n",
       "50%    -7.162650e-02           -1.782793e-01  ... -2.690395e-01   \n",
       "75%     5.307792e-01            4.709834e-01  ...  5.220158e-01   \n",
       "max     4.484751e+00            4.910919e+00  ...  4.094189e+00   \n",
       "\n",
       "       worst texture  worst perimeter  worst area  worst smoothness  \\\n",
       "count   5.690000e+02     5.690000e+02  569.000000      5.690000e+02   \n",
       "mean    1.248757e-17    -3.746271e-16    0.000000     -2.372638e-16   \n",
       "std     1.000880e+00     1.000880e+00    1.000880      1.000880e+00   \n",
       "min    -2.223994e+00    -1.693361e+00   -1.222423     -2.682695e+00   \n",
       "25%    -7.486293e-01    -6.895783e-01   -0.642136     -6.912304e-01   \n",
       "50%    -4.351564e-02    -2.859802e-01   -0.341181     -4.684277e-02   \n",
       "75%     6.583411e-01     5.402790e-01    0.357589      5.975448e-01   \n",
       "max     3.885905e+00     4.287337e+00    5.930172      3.955374e+00   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count       5.690000e+02     5.690000e+02          5.690000e+02   \n",
       "mean       -3.371644e-16     7.492542e-17          2.247763e-16   \n",
       "std         1.000880e+00     1.000880e+00          1.000880e+00   \n",
       "min        -1.443878e+00    -1.305831e+00         -1.745063e+00   \n",
       "25%        -6.810833e-01    -7.565142e-01         -7.563999e-01   \n",
       "50%        -2.695009e-01    -2.182321e-01         -2.234689e-01   \n",
       "75%         5.396688e-01     5.311411e-01          7.125100e-01   \n",
       "max         5.112877e+00     4.700669e+00          2.685877e+00   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count    5.690000e+02             5.690000e+02  \n",
       "mean     2.622390e-16            -5.744282e-16  \n",
       "std      1.000880e+00             1.000880e+00  \n",
       "min     -2.160960e+00            -1.601839e+00  \n",
       "25%     -6.418637e-01            -6.919118e-01  \n",
       "50%     -1.274095e-01            -2.164441e-01  \n",
       "75%      4.501382e-01             4.507624e-01  \n",
       "max      6.046041e+00             6.846856e+00  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's repackage in a dataframe\n",
    "import pandas\n",
    "scaled_data = pandas.DataFrame(scaled_data, columns=data.columns)\n",
    "# and check the result has zero mean and constant standard deviation\n",
    "scaled_data.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83e3ca34-0b0d-42d9-baa6-c989c630cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for compatibility purpose we save the scaled dataframe as data\n",
    "data = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ee6854-83f4-4f18-9e3d-16d576feb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and redo the same training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9d5d6b-686e-47d6-a05d-51bafa3ab8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the training set and the testset\n",
    "data_train, data_test, target_train, target_test = sklearn.model_selection.train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eae2c952-7da1-484b-8407-89df9aadcbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "model = sklearn.linear_model.LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "779f9cb6-4d2d-4a91-9779-8b1144ef8e47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data_train, target_train) # this time, we don't get any error message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faac2318-5c62-43fd-807c-5ff8a35ef2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and actually improve the prediction (which might just be chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea187e4-d6b2-435d-9b28-df959a2742eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.972027972027972"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dd8433",
   "metadata": {},
   "source": [
    "__Use k-fold validation to validate the model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09cb1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# because the dataset is relatively small we didn't set aside a validation set\n",
    "# instead we rely on cross-validation\n",
    "\n",
    "# we split the dataset in 5\n",
    "# this provides 5 different testsets (with 20% of observation) to test the training on the remaining set (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033db97e-aa92-4ebf-9973-d736b7216d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = sklearn.model_selection.KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70b30b9b-f9b2-4c5e-9f7a-659ea3c94cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9736842105263158\n",
      "Score: 0.956140350877193\n",
      "Score: 0.9824561403508771\n",
      "Score: 0.9824561403508771\n",
      "Score: 0.9911504424778761\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for i_train, i_test in kf.split(data):\n",
    "    \n",
    "    # i_train and i_test are indices of observations belonging to one of the two datasets\n",
    "    kf_data_train = data.iloc[i_train,:]\n",
    "    kf_target_train = target.iloc[i_train]\n",
    "    \n",
    "    kf_data_test = data.iloc[i_test,:]\n",
    "    kf_target_test = target.iloc[i_test]\n",
    "    \n",
    "    model_kf = sklearn.linear_model.LogisticRegression()\n",
    "    \n",
    "    # we train the model\n",
    "    model_kf.fit(kf_data_train, kf_target_train)\n",
    "    \n",
    "    # and test it\n",
    "    sc = model_kf.score(kf_data_test, kf_target_test)\n",
    "    \n",
    "    scores.append(sc)\n",
    "    \n",
    "    print(f\"Score: {sc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7db165c-f865-497f-b6b2-80e77d01d8bd",
   "metadata": {},
   "source": [
    "There is some volatility in the scores, but it stays reliably over 95% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2de5e5b-9a6a-4500-bea5-9fcbef7a178f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold validation: mean accuracy 0.9771774569166279\n"
     ]
    }
   ],
   "source": [
    "# to get an estimate of accuracy we can compute the mean:\n",
    "print(f\"KFold validation: mean accuracy {sum(scores)/5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-drunk",
   "metadata": {},
   "source": [
    "__Try with other classifiers. Which one is best?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad220192-0536-4c83-8fac-dfed355278d4",
   "metadata": {},
   "source": [
    "The dataset being relatively small we can try Support Vector Machines, which are known to generalize well (see discussion [here](https://towardsdatascience.com/text-classification-with-extremely-small-datasets-333d322caee2)).\n",
    "\n",
    "We perform a kfold selection exactly as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2395d3a-c9d8-443a-a670-f7b3bb26e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = sklearn.model_selection.KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e8a7a39-aae6-4dd2-978e-17223ee863ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.9473684210526315\n",
      "Score: 0.9649122807017544\n",
      "Score: 0.9736842105263158\n",
      "Score: 0.9912280701754386\n",
      "Score: 0.9734513274336283\n"
     ]
    }
   ],
   "source": [
    "scores_svc = []\n",
    "\n",
    "for i_train, i_test in kf.split(data):\n",
    "    \n",
    "    # i_train and i_test are indices of observations belonging to one of the two datasets\n",
    "    kf_data_train = data.iloc[i_train,:]\n",
    "    kf_target_train = target.iloc[i_train]\n",
    "    \n",
    "    kf_data_test = data.iloc[i_test,:]\n",
    "    kf_target_test = target.iloc[i_test]\n",
    "    \n",
    "    # we just change the following line\n",
    "    model_kf = sklearn.svm.SVC()\n",
    "    \n",
    "    # we train the model\n",
    "    model_kf.fit(kf_data_train, kf_target_train)\n",
    "    \n",
    "    # and test it\n",
    "    sc = model_kf.score(kf_data_test, kf_target_test)\n",
    "    \n",
    "    scores_svc.append(sc)\n",
    "    \n",
    "    print(f\"Score: {sc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "099cdc9e-5f5e-4c31-8e4c-ce503463095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold validation: mean accuracy 0.9701288619779538\n"
     ]
    }
   ],
   "source": [
    "# to get an estimate of accuracy we can compute the mean:\n",
    "print(f\"KFold validation: mean accuracy {sum(scores_svc)/5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ab5ec4-fb3c-4e7e-9a0d-a4d18e7db74a",
   "metadata": {},
   "source": [
    "__Comment__: performance of support vector machine is similar to logistic regression. To assess the gains, we can compare the difference to both estimate (0.007) to the standard deviation of either of two models. Both are geater than 0.01, meaning that the difference between the two models is probably not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28b222b4-f2d8-45bb-90cb-adfb7e63d22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01188053806820839\n",
      "0.0142415326274357\n"
     ]
    }
   ],
   "source": [
    "# we can compute the standard deviation as follows (googld standard deviation python)\n",
    "\n",
    "import numpy \n",
    "print( numpy.std(scores) )\n",
    "print( numpy.std(scores_svc) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ESCPython",
   "language": "python",
   "name": "escpython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
